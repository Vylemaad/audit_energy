{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0bd0fcb-fbcd-4f51-ab34-49651228a51b",
   "metadata": {},
   "source": [
    "## <center> Projet 3 - Parcours Machine Learning :<br/>Consomation électrique de la ville de Seattle </center>\n",
    "\n",
    "<p style=\"text-align:center;\">Vous travaillez pour la ville de Seattle. Pour atteindre son objectif de ville neutre en émissions de carbone en 2050, votre équipe s’intéresse de près aux émissions des bâtiments non destinés à l’habitation.</p>\n",
    "\n",
    "<center><img src=\"image/logo_seattle.png\" alt=\"logo_seattle\" width=\"500\" /></center>\n",
    "\n",
    "##### Les données\n",
    "\n",
    "Les données de consommation sont [à télécharger ici](https://www.kaggle.com/city-of-seattle/sea-building-energy-benchmarking#2015-building-energy-benchmarking.csv).\n",
    "\n",
    "##### Problématique de la ville de Seattle\n",
    "\n",
    "<p style=\"text-align:justify;\">Des relevés minutieux ont été effectués par vos agents en 2015 et en 2016. Cependant, ces relevés sont coûteux à obtenir, et à partir de ceux déjà réalisés, vous voulez tenter de prédire les émissions de CO2 et la consommation totale d’énergie de bâtiments pour lesquels elles n’ont pas encore été mesurées.\n",
    "\n",
    "Votre prédiction se basera sur les données déclaratives du permis d'exploitation commerciale (taille et usage des bâtiments, mention de travaux récents, date de construction..)\n",
    "\n",
    "Vous cherchez également à évaluer l’intérêt de l’\"ENERGY STAR Score\" pour la prédiction d’émissions, qui est fastidieux à calculer avec l’approche utilisée actuellement par votre équipe.</p>\n",
    "\n",
    "##### Votre mission\n",
    "\n",
    "Vous sortez tout juste d’une réunion de brief avec votre équipe. Voici un récapitulatif de votre mission :\n",
    "\n",
    "- Réaliser une courte analyse exploratoire.\n",
    "- Tester différents modèles de prédiction afin de répondre au mieux à la problématique.\n",
    "\n",
    "Avant de quitter la salle de brief, Douglas, le project lead, vous donne quelques pistes, et erreurs à éviter :\n",
    "\n",
    ">L’objectif est de te passer des relevés de consommation annuels (attention à la fuite de données), mais rien ne t'interdit d’en déduire des variables plus simples (nature et proportions des sources d’énergie utilisées). \n",
    ">\n",
    ">Fais bien attention au traitement des différentes variables, à la fois pour trouver de nouvelles informations (peut-on déduire des choses intéressantes d’une simple adresse ?) et optimiser les performances en appliquant des transformations simples aux variables (normalisation, passage au log, etc.).\n",
    ">\n",
    ">Mets en place une évaluation rigoureuse des performances de la régression, et optimise les hyperparamètres et le choix d’algorithme de ML à l’aide d’une validation croisée.\n",
    ">\n",
    "\n",
    "#### Let's go :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45debcd4-6c97-43c2-9dfb-f8c2fda34488",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "####################                       Import librairies                    ###################\n",
    "###################################################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import isnan\n",
    "from global_functions_variables import *\n",
    "\n",
    "\n",
    "center_seattle_loc = {\"latitude\" : 47.6062095, \"longitude\" : -122.3320708}\n",
    "\n",
    "useless_variables = ['SPD Beats', #no idea what it means but no related to energy\n",
    "                     'City Council Districts', #93% of missing values\n",
    "                     'OtherFuelUse(kBtu)', # only 17 actual values\n",
    "                     '2010 Census Tracts', #93% of missing values\n",
    "                     'Outlier', #97% of missing values\n",
    "                     'PropertyGFATotal' #Already have parking and building, use it to check errors\n",
    "                    ]\n",
    "variables_test = ['Seattle Police Department Micro Community Policing Plan Areas',\n",
    "                  'YearsENERGYSTARCertified',\n",
    "                  'ENERGYSTARScore'\n",
    "                 ]\n",
    "\n",
    "variables_train = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760bca56-d736-4eba-a214-727beae7e178",
   "metadata": {},
   "source": [
    "#### Les fichiers CSV :\n",
    "\n",
    "<p>Les relevés énergétiques sont stockés dans 2 fichiers csv :</p>\n",
    "\n",
    "- Les relevés de 2015\n",
    "- Les relevés de 2016\n",
    "\n",
    "<p>On remarque rapidement que les deux bases de données n'ont pas le même nombre de colonnes.\n",
    "Une analyse des différences nous apprend :</p>\n",
    "\n",
    "1. Les variables de localisation du fichier de 2016 :<br>\n",
    "    *Latitude*,<br>\n",
    "    *Longitude*,<br>\n",
    "    *City*,<br>\n",
    "    *Address*,<br>\n",
    "    *zipCode*,<br>\n",
    "    *State*<br> sont **compressées** dans une seule variable *Location* dans le fichier de 2015\n",
    "\n",
    "2. Les variables du fichier 2015 :<br> \n",
    "     *OtherFuelUse(kBtu)*,<br> \n",
    "     *2010 Census Tracts*,<br> \n",
    "     *Seattle Police Department Micro Community Policing Plan Areas*,<br> \n",
    "     *City Council Districts*,<br> \n",
    "     *SPD Beats*,<br>\n",
    "     *Zip Codes*,<br>non présentes en 2016, sont **vides, faussées ou sans rapport avec la consommation d'énergie**\n",
    "    \n",
    "3. Les dernières différences de variables représentent **les mêmes données sous la même métrique** mais **sous un autre nom**.\n",
    "\n",
    "<p>Pour rassembler ces deux bases de données il faut donc :</p>\n",
    "\n",
    "1. Décompresser la variable *Location* de 2015 et sauvegarder ses valeurs dans de nouvelles colonnes de même noms que la version 2016\n",
    "\n",
    "2. Retirer les colonnes non pertinentes du DataFrame de 2015\n",
    "\n",
    "3. Renommer les variables restantes pour s'adapter aux variables de 2016\n",
    "\n",
    "Une fois ces étapes effectuées, les deux DataFrames pourront être combinés afin de traiter les données de 2015 et de 2016 simultanément."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fe56cce-67c4-499b-a70e-acd304f8fc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2016 CSV file had 46 fields and the 2015 CSV file had 47 fields\n",
      "Both datasets have the same number of columns, it could be concatenate now\n",
      "The final shape of 2015-2016 dataset is (6716, 46)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([12., 11., 41., 10., 18.,  2.,  8., 15.,  6., 25.,  9., 33., 28.,\n",
       "        5., 19.,  7.,  1.,  3.,  4., 24., 20., 34.,  0., 16., 23., 17.,\n",
       "       36., 22., 47., 29., 14., 49., 37., 42., 63., 13., 21., 55., 46.,\n",
       "       30., 56., 26., 27., 76., 31., 99., 38., nan, 39., 32., 40.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "####################          Load and merge CSV files from 2015 and 2016       ###################\n",
    "###################################################################################################\n",
    "\n",
    "#read csv file and stock it in dataframe\n",
    "data_2015 = pd.read_csv(r'Data/2015-building-energy-benchmarking.csv',\n",
    "                        sep=',', encoding='utf-8', na_values='')\n",
    "data_2016 = pd.read_csv(r'Data/2016-building-energy-benchmarking.csv',\n",
    "                        sep=',', encoding='utf-8', na_values='')\n",
    "print(f\"The 2016 CSV file had {data_2016.shape[1]}\\\n",
    " fields and the 2015 CSV file had {data_2015.shape[1]} fields\")\n",
    "    \n",
    "# 1.Re-Organize location variables - Dezip latitude, longitude ect..\n",
    "decompressed = {'Latitude': [],\n",
    "                'Longitude' : [],\n",
    "                'City' : [],\n",
    "                'Address' : [],\n",
    "                'ZipCode' : [],\n",
    "                'State': []}\n",
    "\n",
    "for loc in data_2015['Location']:\n",
    "    loc_dict = eval(loc)\n",
    "    address_dict = eval(loc_dict['human_address'])\n",
    "    decompressed['Latitude'].append(loc_dict['latitude'])\n",
    "    decompressed['Longitude'].append(loc_dict['longitude'])\n",
    "    decompressed['City'].append(address_dict['city'])\n",
    "    decompressed['Address'].append(address_dict['address'])\n",
    "    decompressed['ZipCode'].append(address_dict['zip'])\n",
    "    decompressed['State'].append(address_dict['state'])\n",
    "data_2015 = pd.concat([data_2015.drop('Location',axis=1), pd.DataFrame(decompressed)],axis=1)\n",
    "\n",
    "# 2. Remove variables only present in 2015 AND empty, irrelevant or wrong :\n",
    "data_2015.drop([\"OtherFuelUse(kBtu)\",'2010 Census Tracts',\n",
    "                'Seattle Police Department Micro Community Policing Plan Areas',\n",
    "                'City Council Districts',\"SPD Beats\", 'Zip Codes'], axis=1, inplace=True)\n",
    "\n",
    "# For \"GHGEmissions(MetricTonsCO2e) --> TotalGHGEmissions \n",
    "#we have checked beforehand that 2015 and 2016 dataset use the same metrics !\n",
    "\n",
    "# 3. Rename 2015 variable to their 2016 names\n",
    "data_2015.rename(columns={\"Comment\" : \"Comments\",\n",
    "                          \"GHGEmissions(MetricTonsCO2e)\" : \"TotalGHGEmissions\",\n",
    "                         \"GHGEmissionsIntensity(kgCO2e/ft2)\" : \"GHGEmissionsIntensity\"\n",
    "                         },inplace=True)\n",
    "\n",
    "# Finally, combine both into a 2015-2016 dataframe\n",
    "if len(set(data_2016.columns).symmetric_difference(set(data_2015.columns))) == 0 :\n",
    "    print(\"Both datasets have the same number of columns, it could be concatenate now\")\n",
    "    data_energy = pd.concat([data_2015, data_2016], axis=0)\n",
    "else:\n",
    "    print(\"Something gone wrong\")\n",
    "    \n",
    "print(f\"The final shape of 2015-2016 dataset is {data_energy.shape}\")\n",
    "data_energy['NumberofFloors'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954daec0-e14a-4408-bae6-ce85080532e2",
   "metadata": {},
   "source": [
    "#### Première réduction de variables:\n",
    "\n",
    "<p>Notre DataFrame possède 46 variables qu'il faut étudier pour déduire de leur pertinence et de leur impact sur notre projet. Pour cela, observer leur type, leur valeurs uniques, leur valeurs manquantes ou encore leur métrique apporte de précieuses informations.</p> \n",
    "\n",
    "##### Les variables de localisation:\n",
    "\n",
    "<p>Les données de localisation sont importantes pour visualiser nos résultats sur une carte, ou étudier la consommation par quartier. L'emplacement d'un bâtiment est-il corrélé à sa consommation énergétique? Pour le découvrir, il faut conserver ces données. </p>\n",
    "\n",
    "- *Latitude* et *Longitude* :\n",
    "Axe Nord-Sud et Ouest-Est des coordonnées terrestres, permet une localisation précise et pratiquement unique (Utilisable pour détecter les doublons). **à conservé**\n",
    "\n",
    "- *Neighborhood*, *ZipCode* et *CouncilDistrictCode* :\n",
    "Chacune de ces variables représente des zones géographiques définies, à première vue, elles ne semblent pas se recouper et apporte donc des informations différentes. Les valeurs de *Neighborhood* et *ZipCode* ne sont pas standardisées (type string et int cohabitant, orthographe alternative etc...). Attention au boites postales ! Regroupement sous une seule variable à envisager.\n",
    "**à conservé et à standardisé**\n",
    "\n",
    "- *Address* :\n",
    "Représentation \"humaine\" de la position du bâtiment, ne sera pas utilisable par nos systèmes, d'autant plus que de meilleures informations de positionnement existent. **à retirer**\n",
    "\n",
    "- *State* et *City* :\n",
    "Ces variables n'ont qu'une seule valeur possible dans ce jeu de données. **à retirer**\n",
    "\n",
    "\n",
    "##### Les variables de description du bâtiment:\n",
    "\n",
    "<p>Rappel du projet :</p>\n",
    "\n",
    ">Votre prédiction se basera sur les données déclaratives du permis d'exploitation commerciale (taille et usage des bâtiments, mention de travaux récents, date de construction..)\n",
    "\n",
    "<p>Les informations relatives aux bâtiments sont les données de base de notre système, sur lesquels on s'appuieras pour prédire la consommation. La récupération de ces données est peu coûteuse.</p> \n",
    "\n",
    "- *OSEBuildingID* et *TaxParcelIdentificationNumber* et *PropertyName* :\n",
    "Variables d'identification, identifient les bâtiments ( ou leur propriétaire dans le cas de *TaxParcelIdentificationNumber*) par un numéro ou un nom. Utiles pour manipuler les données et détecter les doublons **à conservé**\n",
    "\n",
    "- *YearBuilt*, *NumberofBuildings*, *NumberofFloors* :\n",
    "Variables descriptives du bâtiments.\n",
    "**à conservé**\n",
    "\n",
    "- *PropertyGFATotal*, *PropertyGFAParking*, *PropertyGFABuilding(s)* :\n",
    "GFA signifie Gross Floor Area : la superficie au sol du bâtiment en incluant les murs extérieurs. Ces variables représentent la superficie au sol du bâtiment avec ou sans prendre en compte le parking. La formule *PropertyGFATotal* = *PropertyGFAParking*+*PropertyGFABuilding(s)* semble indiquer une redondance.\n",
    "**redondance : choisir quelles variables conserver ou supprimer**\n",
    "\n",
    "- *BuildingType*, *PrimaryPropertyType*, *ListOfAllPropertyUseTypes* et autres :\n",
    "Type d'usage du bâtiment selon différentes granularités. Si le bâtiment a plus d'un seul type d'usage, la surface au sol allouée aux trois premiers types d'usage est disponible dans les variables *LargestPropertyUseTypeGFA*, *SecondLargestPropertyUseTypeGFA* et *ThirdLargestPropertyUseTypeGFA*. Cette méthode de stockage d'information provoque un fort taux de valeurs manquantes. De plus, une redondance est présente entre *ListOfAllPropertyUseTypes* et les trois variables *LargestPropertyUseType*, *SecondLargestPropertyUseType*, *ThirdLargestPropertyUseType*. Des modifications sur ces variables sont donc à prévoir.\n",
    "**à conservé et à modifié**\n",
    "\n",
    "##### Les variables énergetiques:\n",
    "\n",
    "       'YearsENERGYSTARCertified',\n",
    "       'ENERGYSTARScore', 'SiteEUI(kBtu/sf)', 'SiteEUIWN(kBtu/sf)',\n",
    "       'SourceEUI(kBtu/sf)', 'SourceEUIWN(kBtu/sf)', 'SiteEnergyUse(kBtu)',\n",
    "       'SiteEnergyUseWN(kBtu)', 'SteamUse(kBtu)', 'Electricity(kWh)',\n",
    "       'Electricity(kBtu)', 'NaturalGas(therms)', 'NaturalGas(kBtu)',\n",
    "       'TotalGHGEmissions', 'GHGEmissionsIntensity',\n",
    "       \n",
    "##### Autres variables :\n",
    "\n",
    "       'DefaultData', 'Comments',\n",
    "       'ComplianceStatus', 'Outlier', 'DataYear'\n",
    "\n",
    "##### Conclusion de la réduction des variables :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b067cc6-3231-4a01-9b67-f7c9e07c4c91",
   "metadata": {},
   "source": [
    "#### Nettoyage des données :\n",
    "\n",
    "##### Supprimer les bâtiments résidentiels:\n",
    "\n",
    "<p>Dans l'intitulé du projet il est dit :</p>\n",
    "\n",
    ">Pour atteindre son objectif de ville neutre en émissions de carbone en 2050, votre équipe s’intéresse de près aux émissions **des bâtiments non destinés à l’habitation.**\n",
    "\n",
    "<p>Une première action sera donc de retirer tout les bâtiments résidentiels de notre DataFrame. <br>Pour cela nous étudions les valeurs présentes dans *BuildingType*, nous y découvrons 3 valeurs représentant des bâtiment résidentiels :</p>\n",
    "\n",
    " - Multifamily MR (5-9)\n",
    " - Multifamily LR (1-4)\n",
    " - Multifamily HR (10+)\n",
    " \n",
    "<p>Tout individus ayant ces valeurs dans le champs *BuildingType* est donc retirer de notre DataFrame</p>\n",
    "\n",
    "##### Supprimer les colonnes non pertinentes:\n",
    "\n",
    "<p>Les variables *City* et *State* n'ont qu'une seule valeur possible</p>\n",
    "1. Les variables de localisation du fichier de 2016 :<br>\n",
    "    *Latitude*,<br>\n",
    "    *Longitude*,<br>\n",
    "    *City*,<br>\n",
    "    *Address*,<br>\n",
    "    *zipCode*,<br>\n",
    "    *State*<br> sont **compressées** dans une seule variable *Location* dans le fichier de 2015\n",
    "\n",
    "2. Les variables du fichier 2015 :<br> \n",
    "     *OtherFuelUse(kBtu)*,<br> \n",
    "     *2010 Census Tracts*,<br> \n",
    "     *Seattle Police Department Micro Community Policing Plan Areas*,<br> \n",
    "     *City Council Districts*,<br> \n",
    "     *SPD Beats*,<br>\n",
    "     *Zip Codes*,<br>non présentes en 2016, sont **vides, faussées ou sans rapport avec la consommation d'énergie**\n",
    "    \n",
    "3. Les dernières différences de variables représentent **les mêmes données sous la même métrique** mais **sous un autre nom**.\n",
    "\n",
    "<p>Pour rassembler ces deux bases de données il faut donc :</p>\n",
    "\n",
    "1. Décompresser la variable *Location* de 2015 et sauvegarder ses valeurs dans de nouvelles colonnes de même noms que la version 2016\n",
    "\n",
    "2. Retirer les colonnes non pertinentes du DataFrame de 2015\n",
    "\n",
    "3. Renommer les variables restantes pour s'adapter aux variables de 2016\n",
    "\n",
    "Une fois ces étapes effectuées, les deux DataFrames pourront être combinés afin de traiter les données de 2015 et de 2016 simultanément."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "045a9bbb-9a89-4f18-a958-e07db7b63e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne OSEBuildingID, 1698 valeurs uniques\n",
      "Colonne DataYear, valeurs uniques :\n",
      "[2015 2016]\n",
      "\n",
      "Colonne BuildingType, valeurs uniques :\n",
      "['NonResidential' 'Nonresidential COS' 'SPS-District K-12' 'Campus'\n",
      " 'Nonresidential WA']\n",
      "\n",
      "Colonne PrimaryPropertyType, 30 valeurs uniques\n",
      "Colonne PropertyName, 3204 valeurs uniques\n",
      "Colonne TaxParcelIdentificationNumber, 1835 valeurs uniques\n",
      "Colonne CouncilDistrictCode, valeurs uniques :\n",
      "[7 3 2 4 5 6 1]\n",
      "\n",
      "Colonne Neighborhood, valeurs uniques :\n",
      "['DOWNTOWN' 'SOUTHEAST' 'NORTHEAST' 'EAST' 'CENTRAL' 'NORTH'\n",
      " 'MAGNOLIA / QUEEN ANNE' 'LAKE UNION' 'GREATER DUWAMISH' 'BALLARD'\n",
      " 'NORTHWEST' 'SOUTHWEST' 'DELRIDGE' 'Central' 'Ballard' 'North' 'Delridge'\n",
      " 'Northwest' 'DELRIDGE NEIGHBORHOODS']\n",
      "\n",
      "Colonne YearBuilt, 113 valeurs uniques\n",
      "Colonne NumberofBuildings, valeurs uniques :\n",
      "[  1.   7.  11.  16.   4.   3.  39.   2.  10.   6.   0.  27.  14.   9.\n",
      "   5.  nan   8.  23. 111.]\n",
      "\n",
      "Colonne NumberofFloors, 45 valeurs uniques\n",
      "Colonne PropertyGFATotal, 1667 valeurs uniques\n",
      "Colonne PropertyGFAParking, 366 valeurs uniques\n",
      "Colonne PropertyGFABuilding(s), 1694 valeurs uniques\n",
      "Colonne ListOfAllPropertyUseTypes, 387 valeurs uniques\n",
      "Colonne LargestPropertyUseType, 57 valeurs uniques\n",
      "Colonne LargestPropertyUseTypeGFA, 1694 valeurs uniques\n",
      "Colonne SecondLargestPropertyUseType, 47 valeurs uniques\n",
      "Colonne SecondLargestPropertyUseTypeGFA, 752 valeurs uniques\n",
      "Colonne ThirdLargestPropertyUseType, 40 valeurs uniques\n",
      "Colonne ThirdLargestPropertyUseTypeGFA, 326 valeurs uniques\n",
      "Colonne YearsENERGYSTARCertified, 113 valeurs uniques\n",
      "Colonne ENERGYSTARScore, 100 valeurs uniques\n",
      "Colonne SiteEUI(kBtu/sf), 1824 valeurs uniques\n",
      "Colonne SiteEUIWN(kBtu/sf), 1843 valeurs uniques\n",
      "Colonne SourceEUI(kBtu/sf), 2464 valeurs uniques\n",
      "Colonne SourceEUIWN(kBtu/sf), 2475 valeurs uniques\n",
      "Colonne SiteEnergyUse(kBtu), 3291 valeurs uniques\n",
      "Colonne SiteEnergyUseWN(kBtu), 3272 valeurs uniques\n",
      "Colonne SteamUse(kBtu), 229 valeurs uniques\n",
      "Colonne Electricity(kWh), 3296 valeurs uniques\n",
      "Colonne Electricity(kBtu), 3296 valeurs uniques\n",
      "Colonne NaturalGas(therms), 2331 valeurs uniques\n",
      "Colonne NaturalGas(kBtu), 2362 valeurs uniques\n",
      "Colonne TotalGHGEmissions, 3014 valeurs uniques\n",
      "Colonne GHGEmissionsIntensity, 583 valeurs uniques\n",
      "Colonne DefaultData, valeurs uniques :\n",
      "['No' 'Yes' nan False True]\n",
      "\n",
      "Colonne Comments, valeurs uniques :\n",
      "[nan\n",
      " 'Under construction starting 6/2013 (old building demolished) and ending 9/2016. New Building re-opened 9/2016. Year built changed from 1948 to 2016.'\n",
      " \"Part of McKinstry's campus, property operates a fabrication and production shop and is conditioned by natural gas overhead radiant unit heaters with no cooling. Learn more at www.mckinstry.com.\"\n",
      " \"One of two office buildings on McKinstry's campus partially remodeled in 2009 from warehouse to office space. Served by rooftop air handling units with underfloor VAVs.  Self-performed energy efficiency upgrades in 2015 include a long-term LED lighting re\"\n",
      " 'Part of McKinstry’s campus, this remodeled warehouse is mainly office but includes a full-size basketball court and gym with locker rooms, bistro with a full kitchen, and data center. Served by rooftop package units for heating and cooling. Upgrades inclu'\n",
      " 'Construction completed in mid 2015. The building was unoccupied for most of 2015.'\n",
      " 'Under construction starting 6/2013 (old building demolished) and ending 9/2016. New Building re-opened 9/2016.  Year built changed from 1950 to 2016.'\n",
      " 'Under construction starting 6/2013 (old building demolished) and ending 9/2016. New Building re-opened 9/2016. Year built changed from 1949 to 2016.'\n",
      " 'Under construction starting 6/2015 (old building demolished) and ending 9/2017. New Building re-opens 9/2017. Year built changed from 1954 to 2017.'\n",
      " 'Under construction starting 09/2014 (old building demolished) and ending 9/2017. New Buildings (two) re-open 9/2017. Year built changed from 1953 to 2017.'\n",
      " \"Part of McKinstry's campus, the office space for this building sites on the 3rd floor above a 2-story parking garage and is served by rooftop package units for both heating and cooling. Learn more at www.mckinstryinnovationcenter.com.\"\n",
      " \"Part of McKinstry's campus, property includes a warehouse, a local pipe supplier, and a local insulation contractor.  Learn more at www.mckinstry.com.\"\n",
      " 'Property now has two buildings: Thornton Creek Elementary School and the Decatur Building. New Thornton Creek Elementary built on Decatur Property and under construction from 6/2013 - 9/2016.']\n",
      "\n",
      "Colonne ComplianceStatus, valeurs uniques :\n",
      "['Compliant' 'Error - Correct Default Data' 'Missing Data' 'Non-Compliant']\n",
      "\n",
      "Colonne Outlier, valeurs uniques :\n",
      "[nan 'High Outlier' 'Low Outlier' 'High outlier' 'Low outlier']\n",
      "\n",
      "Colonne Latitude, 3080 valeurs uniques\n",
      "Colonne Longitude, 2977 valeurs uniques\n",
      "Colonne City, valeurs uniques :\n",
      "['SEATTLE' 'Seattle']\n",
      "\n",
      "Colonne Address, 3117 valeurs uniques\n",
      "Colonne ZipCode, 76 valeurs uniques\n",
      "Colonne State, valeurs uniques :\n",
      "['WA']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "####################                   Traitement des données                   ###################\n",
    "###################################################################################################\n",
    "\n",
    "# Traitement des données 1 : Removing residential building from dataset\n",
    "resi_buildings = ['Multifamily MR (5-9)', 'Multifamily LR (1-4)', 'Multifamily HR (10+)']\n",
    "data_energy = data_energy.loc[~data_energy['BuildingType'].isin(resi_buildings)]\n",
    "\n",
    "\n",
    "for column in data_energy.columns:\n",
    "    if data_energy[column].nunique()<20:\n",
    "        print('Colonne {}, valeurs uniques :\\n{}\\n'.format(column, data_energy[column].unique()))\n",
    "    else:\n",
    "        print('Colonne {}, {} valeurs uniques'.format(column, data_energy[column].nunique()))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f54279b6-35e2-4598-aa22-3a479d3a837b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_data_2015' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m generic_name \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarehouse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffice\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapartment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhome depot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretail\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublic storage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m list_set \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m data_doublons \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_data_2015\u001b[49m[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOSEBuildingID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaxParcelIdentificationNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPropertyName\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_doublons\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m data_doublons\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'original_data_2015' is not defined"
     ]
    }
   ],
   "source": [
    "############################      Trouver les doublons       #################################\n",
    "\n",
    "doublons_list = {'coords': [], 'adress' : [], 'name' : [], 'taxNumber' : [], 'BuildId' : []}\n",
    "id_set = set()\n",
    "generic_name = [\"warehouse\",\"office\",\"apartment\",\"home depot\",\"retail\",\"public storage\"]\n",
    "list_set = []\n",
    "data_doublons = original_data_2015[[\"OSEBuildingID\", \"Location\",\"TaxParcelIdentificationNumber\",\"PropertyName\"]]\n",
    "print(data_doublons.shape)\n",
    "for i, val in data_doublons.T.items():\n",
    "    big_set = set()\n",
    "    loc = eval(val['Location'])\n",
    "    lat_long = coords(loc['latitude'], loc['longitude'])\n",
    "    adresse = eval(loc['human_address'])\n",
    "    taxnum = val[\"TaxParcelIdentificationNumber\"]\n",
    "    name = val[\"PropertyName\"]\n",
    "    buildingid = val[\"OSEBuildingID\"]\n",
    "    if lat_long in doublons_list['coords'] :\n",
    "        big_set.add(i)\n",
    "        big_set.add(doublons_list['coords'].index(lat_long))\n",
    "    if adresse in doublons_list['adress'] :\n",
    "        big_set.add(i)\n",
    "        big_set.add(doublons_list['adress'].index(adresse))\n",
    "    if name in doublons_list['name']:\n",
    "        big_set.add(i)\n",
    "        big_set.add(doublons_list['name'].index(name))\n",
    "    if taxnum in doublons_list['taxNumber']:\n",
    "        big_set.add(i)\n",
    "        big_set.add(doublons_list['taxNumber'].index(taxnum))\n",
    "    if buildingid in doublons_list['BuildId']:\n",
    "        big_set.add(i)\n",
    "        big_set.add(doublons_list['BuildId'].index(buildingid))\n",
    "    doublons_list['coords'].append(lat_long)\n",
    "    doublons_list['adress'].append(adresse)\n",
    "    doublons_list['name'].append(name)\n",
    "    doublons_list['taxNumber'].append(taxnum)\n",
    "    doublons_list['BuildId'].append(buildingid)\n",
    "    if len(list_set) == 0 and len(big_set) != 0 :\n",
    "        list_set.append(big_set)\n",
    "    else :\n",
    "        for x in list_set.copy():\n",
    "            if big_set.intersection(x):\n",
    "                #if some elements are intercorrelated, merge the group\n",
    "                list_set[list_set.index(x)] = set.union(x, big_set)\n",
    "                big_set = set() # avoid adding duplicate\n",
    "                break\n",
    "        if len(big_set) != 0 :\n",
    "            # add a new correlated group only if no intersection \n",
    "            list_set.append(big_set)\n",
    "            \n",
    "for s in list_set:   \n",
    "    data_doublons = original_data_2015[[\"OSEBuildingID\", \"Location\",\"TaxParcelIdentificationNumber\",\"PropertyName\"]].iloc[list(s)]\n",
    "    print(data_doublons.shape[0])\n",
    "    print(data_doublons[[\"TaxParcelIdentificationNumber\",\"PropertyName\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf21d9-df5d-4757-8345-758137273333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
